{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rook Patch Classification\n",
    "In this experiment, we classify 2 identical rook patches in terms of their location. We place the rook patch on the top-left and bottom-right of the image. We train a 5x5 filter with zero padded same convolution followed by ReLU, global max pooling and softmax classifier by using SGD optimizer.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "np.random.seed(1988)  # for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(1988)\n",
    "torch.cuda.manual_seed_all(1988)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f421e1690b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the images\n",
    "\n",
    "img1 = plt.imread('class1.png')\n",
    "img2 = plt.imread('class2.png')\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(img1, cmap='gray')\n",
    "plt.subplot(222)\n",
    "plt.imshow(img2, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranging the inputs\n",
    "\n",
    "img1 = np.reshape(img1,(1,1,32,32))\n",
    "img2 = np.reshape(img2,(1,1,32,32))\n",
    "\n",
    "x_train = np.concatenate((img1, img2), axis=0)\n",
    "y_train = np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'images':self.x_train[idx], 'labels':self.y_train[idx]}\n",
    "        return sample\n",
    "\n",
    "train_set = TrainDataset(x_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Design\n",
    "\n",
    "class RookNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(RookNet, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 1, 5, stride=1, padding=2, bias=False)\n",
    "            self.fc1 = nn.Linear(1 * 1 * 1, 2)\n",
    "            self.adap_max = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = self.adap_max(x)\n",
    "            x = x.view(-1, 1 * 1 * 1)\n",
    "            x = self.fc1(x)\n",
    "            return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round  :   1\n",
      "RookNet(\n",
      "  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (fc1): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (adap_max): AdaptiveMaxPool2d(output_size=1)\n",
      ")\n",
      "RookNet training is starting...\n",
      "Epoch:   1\n",
      "Loss: 0.7982 Acc: 0.5000\n",
      "Epoch:   2\n",
      "Loss: 0.7669 Acc: 0.5000\n",
      "Epoch:   3\n",
      "Loss: 0.7332 Acc: 0.0000\n",
      "Epoch:   4\n",
      "Loss: 0.7272 Acc: 0.5000\n",
      "Epoch:   5\n",
      "Loss: 0.7224 Acc: 0.5000\n",
      "Epoch:   6\n",
      "Loss: 0.7164 Acc: 0.5000\n",
      "Epoch:   7\n",
      "Loss: 0.7101 Acc: 0.5000\n",
      "Epoch:   8\n",
      "Loss: 0.7056 Acc: 0.5000\n",
      "Epoch:   9\n",
      "Loss: 0.7050 Acc: 0.5000\n",
      "Epoch:  10\n",
      "Loss: 0.7083 Acc: 0.0000\n",
      "Epoch:  11\n",
      "Loss: 0.7134 Acc: 0.5000\n",
      "Epoch:  12\n",
      "Loss: 0.7174 Acc: 0.5000\n",
      "Epoch:  13\n",
      "Loss: 0.7189 Acc: 0.0000\n",
      "Epoch:  14\n",
      "Loss: 0.7184 Acc: 0.0000\n",
      "Epoch:  15\n",
      "Loss: 0.7164 Acc: 0.0000\n",
      "Epoch:  16\n",
      "Loss: 0.7139 Acc: 0.5000\n",
      "Epoch:  17\n",
      "Loss: 0.7112 Acc: 0.5000\n",
      "Epoch:  18\n",
      "Loss: 0.7090 Acc: 0.5000\n",
      "Epoch:  19\n",
      "Loss: 0.7075 Acc: 0.5000\n",
      "Epoch:  20\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  21\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  22\n",
      "Loss: 0.7072 Acc: 0.0000\n",
      "Epoch:  23\n",
      "Loss: 0.7077 Acc: 0.0000\n",
      "Epoch:  24\n",
      "Loss: 0.7080 Acc: 0.0000\n",
      "Epoch:  25\n",
      "Loss: 0.7083 Acc: 0.0000\n",
      "Epoch:  26\n",
      "Loss: 0.7083 Acc: 0.0000\n",
      "Epoch:  27\n",
      "Loss: 0.7081 Acc: 0.0000\n",
      "Epoch:  28\n",
      "Loss: 0.7078 Acc: 0.0000\n",
      "Epoch:  29\n",
      "Loss: 0.7074 Acc: 0.0000\n",
      "Epoch:  30\n",
      "Loss: 0.7070 Acc: 0.0000\n",
      "Epoch:  31\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  32\n",
      "Loss: 0.7064 Acc: 0.0000\n",
      "Epoch:  33\n",
      "Loss: 0.7062 Acc: 0.0000\n",
      "Epoch:  34\n",
      "Loss: 0.7062 Acc: 0.0000\n",
      "Epoch:  35\n",
      "Loss: 0.7063 Acc: 0.0000\n",
      "Epoch:  36\n",
      "Loss: 0.7064 Acc: 0.0000\n",
      "Epoch:  37\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  38\n",
      "Loss: 0.7067 Acc: 0.0000\n",
      "Epoch:  39\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  40\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  41\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  42\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  43\n",
      "Loss: 0.7067 Acc: 0.0000\n",
      "Epoch:  44\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  45\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  46\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  47\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  48\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  49\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  50\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  51\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  52\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  53\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  54\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  55\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  56\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  57\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  58\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  59\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  60\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  61\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  62\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  63\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  64\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  65\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  66\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  67\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  68\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  69\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  70\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  71\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  72\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  73\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  74\n",
      "Loss: 0.7064 Acc: 0.0000\n",
      "Epoch:  75\n",
      "Loss: 0.7064 Acc: 0.0000\n",
      "Epoch:  76\n",
      "Loss: 0.7064 Acc: 0.0000\n",
      "Epoch:  77\n",
      "Loss: 0.7062 Acc: 0.0000\n",
      "Epoch:  78\n",
      "Loss: 0.7061 Acc: 0.0000\n",
      "Epoch:  79\n",
      "Loss: 0.7056 Acc: 0.0000\n",
      "Epoch:  80\n",
      "Loss: 0.7048 Acc: 0.0000\n",
      "Epoch:  81\n",
      "Loss: 0.7040 Acc: 0.0000\n",
      "Epoch:  82\n",
      "Loss: 0.7026 Acc: 0.0000\n",
      "Epoch:  83\n",
      "Loss: 0.7018 Acc: 0.0000\n",
      "Epoch:  84\n",
      "Loss: 0.6992 Acc: 0.5000\n",
      "Epoch:  85\n",
      "Loss: 0.6942 Acc: 0.5000\n",
      "Epoch:  86\n",
      "Loss: 0.6883 Acc: 0.5000\n",
      "Epoch:  87\n",
      "Loss: 0.6816 Acc: 1.0000\n",
      "Epoch:  88\n",
      "Loss: 0.6726 Acc: 1.0000\n",
      "Epoch:  89\n",
      "Loss: 0.6524 Acc: 1.0000\n",
      "Epoch:  90\n",
      "Loss: 0.6319 Acc: 1.0000\n",
      "Epoch:  91\n",
      "Loss: 0.6143 Acc: 1.0000\n",
      "Epoch:  92\n",
      "Loss: 0.5827 Acc: 1.0000\n",
      "Epoch:  93\n",
      "Loss: 0.5368 Acc: 1.0000\n",
      "Epoch:  94\n",
      "Loss: 0.5138 Acc: 1.0000\n",
      "Epoch:  95\n",
      "Loss: 0.4099 Acc: 1.0000\n",
      "Epoch:  96\n",
      "Loss: 0.3540 Acc: 1.0000\n",
      "Epoch:  97\n",
      "Loss: 0.2977 Acc: 1.0000\n",
      "Epoch:  98\n",
      "Loss: 0.2541 Acc: 1.0000\n",
      "Epoch:  99\n",
      "Loss: 0.1905 Acc: 1.0000\n",
      "Epoch: 100\n",
      "Loss: 0.1538 Acc: 1.0000\n",
      "RookNet testing is starting...\n",
      "testing loss:  0.12532560527324677\n",
      "Accuracy of the network on the test images: 100.0000 %\n",
      "Round  :   2\n",
      "RookNet(\n",
      "  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (fc1): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (adap_max): AdaptiveMaxPool2d(output_size=1)\n",
      ")\n",
      "RookNet training is starting...\n",
      "Epoch:   1\n",
      "Loss: 0.9596 Acc: 0.5000\n",
      "Epoch:   2\n",
      "Loss: 0.7605 Acc: 0.5000\n",
      "Epoch:   3\n",
      "Loss: 0.6752 Acc: 1.0000\n",
      "Epoch:   4\n",
      "Loss: 0.9570 Acc: 0.5000\n",
      "Epoch:   5\n",
      "Loss: 0.9312 Acc: 0.0000\n",
      "Epoch:   6\n",
      "Loss: 0.8140 Acc: 0.5000\n",
      "Epoch:   7\n",
      "Loss: 0.7117 Acc: 0.5000\n",
      "Epoch:   8\n",
      "Loss: 0.7057 Acc: 0.0000\n",
      "Epoch:   9\n",
      "Loss: 0.7341 Acc: 0.5000\n",
      "Epoch:  10\n",
      "Loss: 0.7337 Acc: 0.5000\n",
      "Epoch:  11\n",
      "Loss: 0.7058 Acc: 0.5000\n",
      "Epoch:  12\n",
      "Loss: 0.7058 Acc: 0.5000\n",
      "Epoch:  13\n",
      "Loss: 0.7043 Acc: 0.5000\n",
      "Epoch:  14\n",
      "Loss: 0.7032 Acc: 0.5000\n",
      "Epoch:  15\n",
      "Loss: 0.7016 Acc: 0.5000\n",
      "Epoch:  16\n",
      "Loss: 0.6970 Acc: 0.5000\n",
      "Epoch:  17\n",
      "Loss: 0.6877 Acc: 0.5000\n",
      "Epoch:  18\n",
      "Loss: 0.6719 Acc: 0.5000\n",
      "Epoch:  19\n",
      "Loss: 0.6469 Acc: 0.5000\n",
      "Epoch:  20\n",
      "Loss: 0.6395 Acc: 0.5000\n",
      "Epoch:  21\n",
      "Loss: 0.6101 Acc: 0.5000\n",
      "Epoch:  22\n",
      "Loss: 0.5612 Acc: 1.0000\n",
      "Epoch:  23\n",
      "Loss: 0.5059 Acc: 1.0000\n",
      "Epoch:  24\n",
      "Loss: 0.4862 Acc: 1.0000\n",
      "Epoch:  25\n",
      "Loss: 0.4029 Acc: 1.0000\n",
      "Epoch:  26\n",
      "Loss: 0.3376 Acc: 1.0000\n",
      "Epoch:  27\n",
      "Loss: 0.2939 Acc: 1.0000\n",
      "Epoch:  28\n",
      "Loss: 0.2093 Acc: 1.0000\n",
      "Epoch:  29\n",
      "Loss: 0.1544 Acc: 1.0000\n",
      "Epoch:  30\n",
      "Loss: 0.1107 Acc: 1.0000\n",
      "Epoch:  31\n",
      "Loss: 0.0786 Acc: 1.0000\n",
      "Epoch:  32\n",
      "Loss: 0.0617 Acc: 1.0000\n",
      "Epoch:  33\n",
      "Loss: 0.0503 Acc: 1.0000\n",
      "Epoch:  34\n",
      "Loss: 0.0460 Acc: 1.0000\n",
      "Epoch:  35\n",
      "Loss: 0.0367 Acc: 1.0000\n",
      "Epoch:  36\n",
      "Loss: 0.0319 Acc: 1.0000\n",
      "Epoch:  37\n",
      "Loss: 0.0279 Acc: 1.0000\n",
      "Epoch:  38\n",
      "Loss: 0.0246 Acc: 1.0000\n",
      "Epoch:  39\n",
      "Loss: 0.0218 Acc: 1.0000\n",
      "Epoch:  40\n",
      "Loss: 0.0194 Acc: 1.0000\n",
      "Epoch:  41\n",
      "Loss: 0.0175 Acc: 1.0000\n",
      "Epoch:  42\n",
      "Loss: 0.0159 Acc: 1.0000\n",
      "Epoch:  43\n",
      "Loss: 0.0145 Acc: 1.0000\n",
      "Epoch:  44\n",
      "Loss: 0.0133 Acc: 1.0000\n",
      "Epoch:  45\n",
      "Loss: 0.0124 Acc: 1.0000\n",
      "Epoch:  46\n",
      "Loss: 0.0115 Acc: 1.0000\n",
      "Epoch:  47\n",
      "Loss: 0.0108 Acc: 1.0000\n",
      "Epoch:  48\n",
      "Loss: 0.0102 Acc: 1.0000\n",
      "Epoch:  49\n",
      "Loss: 0.0096 Acc: 1.0000\n",
      "Epoch:  50\n",
      "Loss: 0.0092 Acc: 1.0000\n",
      "Epoch:  51\n",
      "Loss: 0.0089 Acc: 1.0000\n",
      "Epoch:  52\n",
      "Loss: 0.0084 Acc: 1.0000\n",
      "Epoch:  53\n",
      "Loss: 0.0081 Acc: 1.0000\n",
      "Epoch:  54\n",
      "Loss: 0.0078 Acc: 1.0000\n",
      "Epoch:  55\n",
      "Loss: 0.0076 Acc: 1.0000\n",
      "Epoch:  56\n",
      "Loss: 0.0073 Acc: 1.0000\n",
      "Epoch:  57\n",
      "Loss: 0.0071 Acc: 1.0000\n",
      "Epoch:  58\n",
      "Loss: 0.0069 Acc: 1.0000\n",
      "Epoch:  59\n",
      "Loss: 0.0068 Acc: 1.0000\n",
      "Epoch:  60\n",
      "Loss: 0.0066 Acc: 1.0000\n",
      "Epoch:  61\n",
      "Loss: 0.0064 Acc: 1.0000\n",
      "Epoch:  62\n",
      "Loss: 0.0063 Acc: 1.0000\n",
      "Epoch:  63\n",
      "Loss: 0.0061 Acc: 1.0000\n",
      "Epoch:  64\n",
      "Loss: 0.0060 Acc: 1.0000\n",
      "Epoch:  65\n",
      "Loss: 0.0058 Acc: 1.0000\n",
      "Epoch:  66\n",
      "Loss: 0.0057 Acc: 1.0000\n",
      "Epoch:  67\n",
      "Loss: 0.0056 Acc: 1.0000\n",
      "Epoch:  68\n",
      "Loss: 0.0055 Acc: 1.0000\n",
      "Epoch:  69\n",
      "Loss: 0.0054 Acc: 1.0000\n",
      "Epoch:  70\n",
      "Loss: 0.0053 Acc: 1.0000\n",
      "Epoch:  71\n",
      "Loss: 0.0052 Acc: 1.0000\n",
      "Epoch:  72\n",
      "Loss: 0.0051 Acc: 1.0000\n",
      "Epoch:  73\n",
      "Loss: 0.0050 Acc: 1.0000\n",
      "Epoch:  74\n",
      "Loss: 0.0049 Acc: 1.0000\n",
      "Epoch:  75\n",
      "Loss: 0.0048 Acc: 1.0000\n",
      "Epoch:  76\n",
      "Loss: 0.0047 Acc: 1.0000\n",
      "Epoch:  77\n",
      "Loss: 0.0047 Acc: 1.0000\n",
      "Epoch:  78\n",
      "Loss: 0.0046 Acc: 1.0000\n",
      "Epoch:  79\n",
      "Loss: 0.0045 Acc: 1.0000\n",
      "Epoch:  80\n",
      "Loss: 0.0044 Acc: 1.0000\n",
      "Epoch:  81\n",
      "Loss: 0.0044 Acc: 1.0000\n",
      "Epoch:  82\n",
      "Loss: 0.0043 Acc: 1.0000\n",
      "Epoch:  83\n",
      "Loss: 0.0042 Acc: 1.0000\n",
      "Epoch:  84\n",
      "Loss: 0.0042 Acc: 1.0000\n",
      "Epoch:  85\n",
      "Loss: 0.0042 Acc: 1.0000\n",
      "Epoch:  86\n",
      "Loss: 0.0041 Acc: 1.0000\n",
      "Epoch:  87\n",
      "Loss: 0.0041 Acc: 1.0000\n",
      "Epoch:  88\n",
      "Loss: 0.0040 Acc: 1.0000\n",
      "Epoch:  89\n",
      "Loss: 0.0040 Acc: 1.0000\n",
      "Epoch:  90\n",
      "Loss: 0.0039 Acc: 1.0000\n",
      "Epoch:  91\n",
      "Loss: 0.0039 Acc: 1.0000\n",
      "Epoch:  92\n",
      "Loss: 0.0038 Acc: 1.0000\n",
      "Epoch:  93\n",
      "Loss: 0.0038 Acc: 1.0000\n",
      "Epoch:  94\n",
      "Loss: 0.0037 Acc: 1.0000\n",
      "Epoch:  95\n",
      "Loss: 0.0037 Acc: 1.0000\n",
      "Epoch:  96\n",
      "Loss: 0.0036 Acc: 1.0000\n",
      "Epoch:  97\n",
      "Loss: 0.0036 Acc: 1.0000\n",
      "Epoch:  98\n",
      "Loss: 0.0035 Acc: 1.0000\n",
      "Epoch:  99\n",
      "Loss: 0.0035 Acc: 1.0000\n",
      "Epoch: 100\n",
      "Loss: 0.0035 Acc: 1.0000\n",
      "RookNet testing is starting...\n",
      "testing loss:  0.0034297167148906738\n",
      "Accuracy of the network on the test images: 100.0000 %\n",
      "Round  :   3\n",
      "RookNet(\n",
      "  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (fc1): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (adap_max): AdaptiveMaxPool2d(output_size=1)\n",
      ")\n",
      "RookNet training is starting...\n",
      "Epoch:   1\n",
      "Loss: 0.7346 Acc: 0.5000\n",
      "Epoch:   2\n",
      "Loss: 0.7251 Acc: 0.5000\n",
      "Epoch:   3\n",
      "Loss: 0.7105 Acc: 0.5000\n",
      "Epoch:   4\n",
      "Loss: 0.6998 Acc: 0.5000\n",
      "Epoch:   5\n",
      "Loss: 0.6970 Acc: 0.5000\n",
      "Epoch:   6\n",
      "Loss: 0.7011 Acc: 0.5000\n",
      "Epoch:   7\n",
      "Loss: 0.7042 Acc: 0.5000\n",
      "Epoch:   8\n",
      "Loss: 0.7077 Acc: 0.5000\n",
      "Epoch:   9\n",
      "Loss: 0.7103 Acc: 0.5000\n",
      "Epoch:  10\n",
      "Loss: 0.7118 Acc: 0.5000\n",
      "Epoch:  11\n",
      "Loss: 0.7122 Acc: 0.5000\n",
      "Epoch:  12\n",
      "Loss: 0.7117 Acc: 0.0000\n",
      "Epoch:  13\n",
      "Loss: 0.7107 Acc: 0.0000\n",
      "Epoch:  14\n",
      "Loss: 0.7093 Acc: 0.5000\n",
      "Epoch:  15\n",
      "Loss: 0.7078 Acc: 0.5000\n",
      "Epoch:  16\n",
      "Loss: 0.7063 Acc: 0.5000\n",
      "Epoch:  17\n",
      "Loss: 0.7052 Acc: 0.5000\n",
      "Epoch:  18\n",
      "Loss: 0.7047 Acc: 0.5000\n",
      "Epoch:  19\n",
      "Loss: 0.7047 Acc: 0.0000\n",
      "Epoch:  20\n",
      "Loss: 0.7051 Acc: 0.0000\n",
      "Epoch:  21\n",
      "Loss: 0.7059 Acc: 0.0000\n",
      "Epoch:  22\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  23\n",
      "Loss: 0.7072 Acc: 0.0000\n",
      "Epoch:  24\n",
      "Loss: 0.7076 Acc: 0.0000\n",
      "Epoch:  25\n",
      "Loss: 0.7078 Acc: 0.0000\n",
      "Epoch:  26\n",
      "Loss: 0.7077 Acc: 0.0000\n",
      "Epoch:  27\n",
      "Loss: 0.7074 Acc: 0.0000\n",
      "Epoch:  28\n",
      "Loss: 0.7071 Acc: 0.0000\n",
      "Epoch:  29\n",
      "Loss: 0.7067 Acc: 0.0000\n",
      "Epoch:  30\n",
      "Loss: 0.7064 Acc: 0.0000\n",
      "Epoch:  31\n",
      "Loss: 0.7062 Acc: 0.0000\n",
      "Epoch:  32\n",
      "Loss: 0.7061 Acc: 0.0000\n",
      "Epoch:  33\n",
      "Loss: 0.7061 Acc: 0.0000\n",
      "Epoch:  34\n",
      "Loss: 0.7062 Acc: 0.0000\n",
      "Epoch:  35\n",
      "Loss: 0.7064 Acc: 0.0000\n",
      "Epoch:  36\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  37\n",
      "Loss: 0.7067 Acc: 0.0000\n",
      "Epoch:  38\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  39\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  40\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  41\n",
      "Loss: 0.7068 Acc: 0.0000\n",
      "Epoch:  42\n",
      "Loss: 0.7067 Acc: 0.0000\n",
      "Epoch:  43\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  44\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  45\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  46\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  47\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  48\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  49\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  50\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  51\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  52\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  53\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  54\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  55\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  56\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  57\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  58\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  59\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  60\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  61\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  62\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  63\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  64\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  65\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  66\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  67\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  68\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  69\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  70\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  71\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  72\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  73\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  74\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  75\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  76\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  77\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  78\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  79\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  80\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  81\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  82\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  83\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  84\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  85\n",
      "Loss: 0.7066 Acc: 0.0000\n",
      "Epoch:  86\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  87\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  88\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  89\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  90\n",
      "Loss: 0.7065 Acc: 0.0000\n",
      "Epoch:  91\n",
      "Loss: 0.7064 Acc: 0.0000\n",
      "Epoch:  92\n",
      "Loss: 0.7063 Acc: 0.0000\n",
      "Epoch:  93\n",
      "Loss: 0.7063 Acc: 0.0000\n",
      "Epoch:  94\n",
      "Loss: 0.7060 Acc: 0.0000\n",
      "Epoch:  95\n",
      "Loss: 0.7058 Acc: 0.0000\n",
      "Epoch:  96\n",
      "Loss: 0.7055 Acc: 0.0000\n",
      "Epoch:  97\n",
      "Loss: 0.7050 Acc: 0.0000\n",
      "Epoch:  98\n",
      "Loss: 0.7037 Acc: 0.0000\n",
      "Epoch:  99\n",
      "Loss: 0.7020 Acc: 0.0000\n",
      "Epoch: 100\n",
      "Loss: 0.6990 Acc: 0.5000\n",
      "RookNet testing is starting...\n",
      "testing loss:  0.6790423393249512\n",
      "Accuracy of the network on the test images: 100.0000 %\n",
      "Round  :   4\n",
      "RookNet(\n",
      "  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (fc1): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (adap_max): AdaptiveMaxPool2d(output_size=1)\n",
      ")\n",
      "RookNet training is starting...\n",
      "Epoch:   1\n",
      "Loss: 0.8159 Acc: 0.5000\n",
      "Epoch:   2\n",
      "Loss: 0.7749 Acc: 0.5000\n",
      "Epoch:   3\n",
      "Loss: 0.7171 Acc: 0.5000\n",
      "Epoch:   4\n",
      "Loss: 0.6801 Acc: 0.5000\n",
      "Epoch:   5\n",
      "Loss: 0.6764 Acc: 0.5000\n",
      "Epoch:   6\n",
      "Loss: 0.7032 Acc: 0.5000\n",
      "Epoch:   7\n",
      "Loss: 0.7308 Acc: 0.5000\n",
      "Epoch:   8\n",
      "Loss: 0.7403 Acc: 0.5000\n",
      "Epoch:   9\n",
      "Loss: 0.7353 Acc: 0.5000\n",
      "Epoch:  10\n",
      "Loss: 0.7258 Acc: 0.5000\n",
      "Epoch:  11\n",
      "Loss: 0.7179 Acc: 0.0000\n",
      "Epoch:  12\n",
      "Loss: 0.7141 Acc: 0.5000\n",
      "Epoch:  13\n",
      "Loss: 0.7112 Acc: 0.5000\n",
      "Epoch:  14\n",
      "Loss: 0.7077 Acc: 0.5000\n",
      "Epoch:  15\n",
      "Loss: 0.7037 Acc: 0.5000\n",
      "Epoch:  16\n",
      "Loss: 0.7002 Acc: 0.5000\n",
      "Epoch:  17\n",
      "Loss: 0.6979 Acc: 0.5000\n",
      "Epoch:  18\n",
      "Loss: 0.6969 Acc: 0.0000\n",
      "Epoch:  19\n",
      "Loss: 0.6967 Acc: 0.5000\n",
      "Epoch:  20\n",
      "Loss: 0.6966 Acc: 0.5000\n",
      "Epoch:  21\n",
      "Loss: 0.6955 Acc: 0.5000\n",
      "Epoch:  22\n",
      "Loss: 0.6921 Acc: 0.5000\n",
      "Epoch:  23\n",
      "Loss: 0.6852 Acc: 0.5000\n",
      "Epoch:  24\n",
      "Loss: 0.6776 Acc: 0.5000\n",
      "Epoch:  25\n",
      "Loss: 0.6629 Acc: 0.5000\n",
      "Epoch:  26\n",
      "Loss: 0.6466 Acc: 0.5000\n",
      "Epoch:  27\n",
      "Loss: 0.6241 Acc: 0.5000\n",
      "Epoch:  28\n",
      "Loss: 0.6400 Acc: 0.5000\n",
      "Epoch:  29\n",
      "Loss: 0.6082 Acc: 0.5000\n",
      "Epoch:  30\n",
      "Loss: 0.5685 Acc: 1.0000\n",
      "Epoch:  31\n",
      "Loss: 0.5310 Acc: 1.0000\n",
      "Epoch:  32\n",
      "Loss: 0.4850 Acc: 1.0000\n",
      "Epoch:  33\n",
      "Loss: 0.4190 Acc: 1.0000\n",
      "Epoch:  34\n",
      "Loss: 0.3717 Acc: 1.0000\n",
      "Epoch:  35\n",
      "Loss: 0.3711 Acc: 1.0000\n",
      "Epoch:  36\n",
      "Loss: 0.3164 Acc: 1.0000\n",
      "Epoch:  37\n",
      "Loss: 0.2513 Acc: 1.0000\n",
      "Epoch:  38\n",
      "Loss: 0.1833 Acc: 1.0000\n",
      "Epoch:  39\n",
      "Loss: 0.1948 Acc: 1.0000\n",
      "Epoch:  40\n",
      "Loss: 0.1656 Acc: 1.0000\n",
      "Epoch:  41\n",
      "Loss: 0.1233 Acc: 1.0000\n",
      "Epoch:  42\n",
      "Loss: 0.1009 Acc: 1.0000\n",
      "Epoch:  43\n",
      "Loss: 0.0765 Acc: 1.0000\n",
      "Epoch:  44\n",
      "Loss: 0.0700 Acc: 1.0000\n",
      "Epoch:  45\n",
      "Loss: 0.0608 Acc: 1.0000\n",
      "Epoch:  46\n",
      "Loss: 0.0517 Acc: 1.0000\n",
      "Epoch:  47\n",
      "Loss: 0.0453 Acc: 1.0000\n",
      "Epoch:  48\n",
      "Loss: 0.0386 Acc: 1.0000\n",
      "Epoch:  49\n",
      "Loss: 0.0376 Acc: 1.0000\n",
      "Epoch:  50\n",
      "Loss: 0.0326 Acc: 1.0000\n",
      "Epoch:  51\n",
      "Loss: 0.0271 Acc: 1.0000\n",
      "Epoch:  52\n",
      "Loss: 0.0232 Acc: 1.0000\n",
      "Epoch:  53\n",
      "Loss: 0.0220 Acc: 1.0000\n",
      "Epoch:  54\n",
      "Loss: 0.0212 Acc: 1.0000\n",
      "Epoch:  55\n",
      "Loss: 0.0198 Acc: 1.0000\n",
      "Epoch:  56\n",
      "Loss: 0.0180 Acc: 1.0000\n",
      "Epoch:  57\n",
      "Loss: 0.0163 Acc: 1.0000\n",
      "Epoch:  58\n",
      "Loss: 0.0152 Acc: 1.0000\n",
      "Epoch:  59\n",
      "Loss: 0.0141 Acc: 1.0000\n",
      "Epoch:  60\n",
      "Loss: 0.0138 Acc: 1.0000\n",
      "Epoch:  61\n",
      "Loss: 0.0132 Acc: 1.0000\n",
      "Epoch:  62\n",
      "Loss: 0.0122 Acc: 1.0000\n",
      "Epoch:  63\n",
      "Loss: 0.0114 Acc: 1.0000\n",
      "Epoch:  64\n",
      "Loss: 0.0110 Acc: 1.0000\n",
      "Epoch:  65\n",
      "Loss: 0.0110 Acc: 1.0000\n",
      "Epoch:  66\n",
      "Loss: 0.0107 Acc: 1.0000\n",
      "Epoch:  67\n",
      "Loss: 0.0102 Acc: 1.0000\n",
      "Epoch:  68\n",
      "Loss: 0.0099 Acc: 1.0000\n",
      "Epoch:  69\n",
      "Loss: 0.0096 Acc: 1.0000\n",
      "Epoch:  70\n",
      "Loss: 0.0091 Acc: 1.0000\n",
      "Epoch:  71\n",
      "Loss: 0.0086 Acc: 1.0000\n",
      "Epoch:  72\n",
      "Loss: 0.0086 Acc: 1.0000\n",
      "Epoch:  73\n",
      "Loss: 0.0085 Acc: 1.0000\n",
      "Epoch:  74\n",
      "Loss: 0.0083 Acc: 1.0000\n",
      "Epoch:  75\n",
      "Loss: 0.0080 Acc: 1.0000\n",
      "Epoch:  76\n",
      "Loss: 0.0078 Acc: 1.0000\n",
      "Epoch:  77\n",
      "Loss: 0.0075 Acc: 1.0000\n",
      "Epoch:  78\n",
      "Loss: 0.0072 Acc: 1.0000\n",
      "Epoch:  79\n",
      "Loss: 0.0072 Acc: 1.0000\n",
      "Epoch:  80\n",
      "Loss: 0.0071 Acc: 1.0000\n",
      "Epoch:  81\n",
      "Loss: 0.0069 Acc: 1.0000\n",
      "Epoch:  82\n",
      "Loss: 0.0067 Acc: 1.0000\n",
      "Epoch:  83\n",
      "Loss: 0.0065 Acc: 1.0000\n",
      "Epoch:  84\n",
      "Loss: 0.0063 Acc: 1.0000\n",
      "Epoch:  85\n",
      "Loss: 0.0062 Acc: 1.0000\n",
      "Epoch:  86\n",
      "Loss: 0.0061 Acc: 1.0000\n",
      "Epoch:  87\n",
      "Loss: 0.0060 Acc: 1.0000\n",
      "Epoch:  88\n",
      "Loss: 0.0059 Acc: 1.0000\n",
      "Epoch:  89\n",
      "Loss: 0.0058 Acc: 1.0000\n",
      "Epoch:  90\n",
      "Loss: 0.0057 Acc: 1.0000\n",
      "Epoch:  91\n",
      "Loss: 0.0055 Acc: 1.0000\n",
      "Epoch:  92\n",
      "Loss: 0.0054 Acc: 1.0000\n",
      "Epoch:  93\n",
      "Loss: 0.0054 Acc: 1.0000\n",
      "Epoch:  94\n",
      "Loss: 0.0053 Acc: 1.0000\n",
      "Epoch:  95\n",
      "Loss: 0.0052 Acc: 1.0000\n",
      "Epoch:  96\n",
      "Loss: 0.0051 Acc: 1.0000\n",
      "Epoch:  97\n",
      "Loss: 0.0050 Acc: 1.0000\n",
      "Epoch:  98\n",
      "Loss: 0.0049 Acc: 1.0000\n",
      "Epoch:  99\n",
      "Loss: 0.0048 Acc: 1.0000\n",
      "Epoch: 100\n",
      "Loss: 0.0048 Acc: 1.0000\n",
      "RookNet testing is starting...\n",
      "testing loss:  0.004709787084721029\n",
      "Accuracy of the network on the test images: 100.0000 %\n",
      "Round  :   5\n",
      "RookNet(\n",
      "  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (fc1): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (adap_max): AdaptiveMaxPool2d(output_size=1)\n",
      ")\n",
      "RookNet training is starting...\n",
      "Epoch:   1\n",
      "Loss: 0.7914 Acc: 0.5000\n",
      "Epoch:   2\n",
      "Loss: 0.7579 Acc: 0.5000\n",
      "Epoch:   3\n",
      "Loss: 0.7390 Acc: 0.5000\n",
      "Epoch:   4\n",
      "Loss: 0.7308 Acc: 0.5000\n",
      "Epoch:   5\n",
      "Loss: 0.7263 Acc: 0.5000\n",
      "Epoch:   6\n",
      "Loss: 0.7209 Acc: 0.5000\n",
      "Epoch:   7\n",
      "Loss: 0.7108 Acc: 0.5000\n",
      "Epoch:   8\n",
      "Loss: 0.6976 Acc: 0.5000\n",
      "Epoch:   9\n",
      "Loss: 0.6851 Acc: 0.5000\n",
      "Epoch:  10\n",
      "Loss: 0.6787 Acc: 1.0000\n",
      "Epoch:  11\n",
      "Loss: 0.6768 Acc: 0.5000\n",
      "Epoch:  12\n",
      "Loss: 0.6742 Acc: 0.5000\n",
      "Epoch:  13\n",
      "Loss: 0.6719 Acc: 0.5000\n",
      "Epoch:  14\n",
      "Loss: 0.6632 Acc: 0.5000\n",
      "Epoch:  15\n",
      "Loss: 0.6412 Acc: 0.5000\n",
      "Epoch:  16\n",
      "Loss: 0.6124 Acc: 0.5000\n",
      "Epoch:  17\n",
      "Loss: 0.5966 Acc: 0.5000\n",
      "Epoch:  18\n",
      "Loss: 0.5557 Acc: 1.0000\n",
      "Epoch:  19\n",
      "Loss: 0.5023 Acc: 1.0000\n",
      "Epoch:  20\n",
      "Loss: 0.4497 Acc: 1.0000\n",
      "Epoch:  21\n",
      "Loss: 0.3872 Acc: 1.0000\n",
      "Epoch:  22\n",
      "Loss: 0.3179 Acc: 1.0000\n",
      "Epoch:  23\n",
      "Loss: 0.2830 Acc: 1.0000\n",
      "Epoch:  24\n",
      "Loss: 0.2212 Acc: 1.0000\n",
      "Epoch:  25\n",
      "Loss: 0.1758 Acc: 1.0000\n",
      "Epoch:  26\n",
      "Loss: 0.1346 Acc: 1.0000\n",
      "Epoch:  27\n",
      "Loss: 0.1031 Acc: 1.0000\n",
      "Epoch:  28\n",
      "Loss: 0.0946 Acc: 1.0000\n",
      "Epoch:  29\n",
      "Loss: 0.0685 Acc: 1.0000\n",
      "Epoch:  30\n",
      "Loss: 0.0567 Acc: 1.0000\n",
      "Epoch:  31\n",
      "Loss: 0.0471 Acc: 1.0000\n",
      "Epoch:  32\n",
      "Loss: 0.0394 Acc: 1.0000\n",
      "Epoch:  33\n",
      "Loss: 0.0333 Acc: 1.0000\n",
      "Epoch:  34\n",
      "Loss: 0.0285 Acc: 1.0000\n",
      "Epoch:  35\n",
      "Loss: 0.0254 Acc: 1.0000\n",
      "Epoch:  36\n",
      "Loss: 0.0225 Acc: 1.0000\n",
      "Epoch:  37\n",
      "Loss: 0.0201 Acc: 1.0000\n",
      "Epoch:  38\n",
      "Loss: 0.0183 Acc: 1.0000\n",
      "Epoch:  39\n",
      "Loss: 0.0168 Acc: 1.0000\n",
      "Epoch:  40\n",
      "Loss: 0.0155 Acc: 1.0000\n",
      "Epoch:  41\n",
      "Loss: 0.0144 Acc: 1.0000\n",
      "Epoch:  42\n",
      "Loss: 0.0134 Acc: 1.0000\n",
      "Epoch:  43\n",
      "Loss: 0.0126 Acc: 1.0000\n",
      "Epoch:  44\n",
      "Loss: 0.0118 Acc: 1.0000\n",
      "Epoch:  45\n",
      "Loss: 0.0122 Acc: 1.0000\n",
      "Epoch:  46\n",
      "Loss: 0.0109 Acc: 1.0000\n",
      "Epoch:  47\n",
      "Loss: 0.0106 Acc: 1.0000\n",
      "Epoch:  48\n",
      "Loss: 0.0102 Acc: 1.0000\n",
      "Epoch:  49\n",
      "Loss: 0.0099 Acc: 1.0000\n",
      "Epoch:  50\n",
      "Loss: 0.0096 Acc: 1.0000\n",
      "Epoch:  51\n",
      "Loss: 0.0092 Acc: 1.0000\n",
      "Epoch:  52\n",
      "Loss: 0.0089 Acc: 1.0000\n",
      "Epoch:  53\n",
      "Loss: 0.0086 Acc: 1.0000\n",
      "Epoch:  54\n",
      "Loss: 0.0083 Acc: 1.0000\n",
      "Epoch:  55\n",
      "Loss: 0.0081 Acc: 1.0000\n",
      "Epoch:  56\n",
      "Loss: 0.0078 Acc: 1.0000\n",
      "Epoch:  57\n",
      "Loss: 0.0076 Acc: 1.0000\n",
      "Epoch:  58\n",
      "Loss: 0.0074 Acc: 1.0000\n",
      "Epoch:  59\n",
      "Loss: 0.0073 Acc: 1.0000\n",
      "Epoch:  60\n",
      "Loss: 0.0071 Acc: 1.0000\n",
      "Epoch:  61\n",
      "Loss: 0.0069 Acc: 1.0000\n",
      "Epoch:  62\n",
      "Loss: 0.0068 Acc: 1.0000\n",
      "Epoch:  63\n",
      "Loss: 0.0066 Acc: 1.0000\n",
      "Epoch:  64\n",
      "Loss: 0.0065 Acc: 1.0000\n",
      "Epoch:  65\n",
      "Loss: 0.0064 Acc: 1.0000\n",
      "Epoch:  66\n",
      "Loss: 0.0062 Acc: 1.0000\n",
      "Epoch:  67\n",
      "Loss: 0.0062 Acc: 1.0000\n",
      "Epoch:  68\n",
      "Loss: 0.0061 Acc: 1.0000\n",
      "Epoch:  69\n",
      "Loss: 0.0060 Acc: 1.0000\n",
      "Epoch:  70\n",
      "Loss: 0.0059 Acc: 1.0000\n",
      "Epoch:  71\n",
      "Loss: 0.0058 Acc: 1.0000\n",
      "Epoch:  72\n",
      "Loss: 0.0057 Acc: 1.0000\n",
      "Epoch:  73\n",
      "Loss: 0.0056 Acc: 1.0000\n",
      "Epoch:  74\n",
      "Loss: 0.0055 Acc: 1.0000\n",
      "Epoch:  75\n",
      "Loss: 0.0054 Acc: 1.0000\n",
      "Epoch:  76\n",
      "Loss: 0.0053 Acc: 1.0000\n",
      "Epoch:  77\n",
      "Loss: 0.0052 Acc: 1.0000\n",
      "Epoch:  78\n",
      "Loss: 0.0052 Acc: 1.0000\n",
      "Epoch:  79\n",
      "Loss: 0.0051 Acc: 1.0000\n",
      "Epoch:  80\n",
      "Loss: 0.0051 Acc: 1.0000\n",
      "Epoch:  81\n",
      "Loss: 0.0050 Acc: 1.0000\n",
      "Epoch:  82\n",
      "Loss: 0.0049 Acc: 1.0000\n",
      "Epoch:  83\n",
      "Loss: 0.0049 Acc: 1.0000\n",
      "Epoch:  84\n",
      "Loss: 0.0048 Acc: 1.0000\n",
      "Epoch:  85\n",
      "Loss: 0.0047 Acc: 1.0000\n",
      "Epoch:  86\n",
      "Loss: 0.0047 Acc: 1.0000\n",
      "Epoch:  87\n",
      "Loss: 0.0046 Acc: 1.0000\n",
      "Epoch:  88\n",
      "Loss: 0.0045 Acc: 1.0000\n",
      "Epoch:  89\n",
      "Loss: 0.0045 Acc: 1.0000\n",
      "Epoch:  90\n",
      "Loss: 0.0044 Acc: 1.0000\n",
      "Epoch:  91\n",
      "Loss: 0.0044 Acc: 1.0000\n",
      "Epoch:  92\n",
      "Loss: 0.0043 Acc: 1.0000\n",
      "Epoch:  93\n",
      "Loss: 0.0043 Acc: 1.0000\n",
      "Epoch:  94\n",
      "Loss: 0.0042 Acc: 1.0000\n",
      "Epoch:  95\n",
      "Loss: 0.0042 Acc: 1.0000\n",
      "Epoch:  96\n",
      "Loss: 0.0042 Acc: 1.0000\n",
      "Epoch:  97\n",
      "Loss: 0.0041 Acc: 1.0000\n",
      "Epoch:  98\n",
      "Loss: 0.0041 Acc: 1.0000\n",
      "Epoch:  99\n",
      "Loss: 0.0040 Acc: 1.0000\n",
      "Epoch: 100\n",
      "Loss: 0.0040 Acc: 1.0000\n",
      "RookNet testing is starting...\n",
      "testing loss:  0.003913025779183954\n",
      "Accuracy of the network on the test images: 100.0000 %\n"
     ]
    }
   ],
   "source": [
    "# Training the network with 5 different initilizations\n",
    "\n",
    "for m in range(5):\n",
    "    print('Round  :{:4d}'.format(m + 1))    \n",
    "    \n",
    "    torch.manual_seed(m) # to try different weight init\n",
    "    rooknet = RookNet()\n",
    "    if use_gpu:\n",
    "        rooknet = rooknet.cuda() \n",
    "    print(rooknet)          \n",
    "     \n",
    "    #******************************************************************#\n",
    "    ###******************** ROOK TRAINING/TESTING *******************###\n",
    "    #******************************************************************#\n",
    "\n",
    "    # Loss functions and optimizer\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD([{'params':rooknet.parameters()}], lr=0.1, momentum=0.9)\n",
    "    \n",
    "    # Training\n",
    "\n",
    "    print('RookNet training is starting...')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        training_loss = 0.0\n",
    "        counter = 0.0\n",
    "        total = 0.0\n",
    "        corrects = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs = data['images']\n",
    "            labels = data['labels']\n",
    "            inputs = inputs.type(torch.FloatTensor)\n",
    "            labels = labels.view(inputs.shape[0])\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = rooknet(inputs) \n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.item()\n",
    "            corrects += torch.sum(predicted == labels)\n",
    "            counter += 1\n",
    "            total += labels.shape[0]\n",
    "\n",
    "        epoch_loss = training_loss / (counter) \n",
    "        epoch_acc = corrects.item() / (total)\n",
    "        print('Epoch:{:4d}'.format(epoch + 1))\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "    \n",
    "    # Testing\n",
    "\n",
    "    print('RookNet testing is starting...')\n",
    "\n",
    "    testing_loss = 0.0\n",
    "    corrects = 0.0\n",
    "    total = 0.0\n",
    "    for data in trainloader:\n",
    "        images = data['images']\n",
    "        images = images.type(torch.FloatTensor)\n",
    "        labels = data['labels']\n",
    "        labels = labels.view(images.shape[0])\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        \n",
    "        if use_gpu:\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "        outputs = rooknet(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        testing_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        corrects +=  torch.sum(predicted == labels)\n",
    "\n",
    "    testing_loss /= total\n",
    "    acc = 100 * corrects.item() / (total)\n",
    "    print('testing loss: ',testing_loss)   \n",
    "    print('Accuracy of the network on the test images: %.4f %%' % (acc))\n",
    "\n",
    "    results[m] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rook results:  {0: 100.0, 1: 100.0, 2: 100.0, 3: 100.0, 4: 100.0}\n",
      "mean: 100.0000 std: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Printing the results and statistics\n",
    "\n",
    "print('rook results: ',results)\n",
    "\n",
    "acc = np.zeros(m+1)\n",
    "\n",
    "for i in range(m+1):\n",
    "    acc[i] = results[i]\n",
    "       \n",
    "mean = np.mean(acc)    \n",
    "std = np.std(acc)\n",
    "\n",
    "print('mean: {:.4f} std: {:.4f}'.format(mean, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
